<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Linear Model Selection and Regularization | ISLR tidymodels Labs</title>
<meta name="author" content="Emil Hvitfeldt">
<meta name="description" content="This lab will take a look at regularization models and hyperparameter tuning. These models are related to the models we saw in chapter 3 and 4, with the difference that they contain a...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 6 Linear Model Selection and Regularization | ISLR tidymodels Labs">
<meta property="og:type" content="book">
<meta property="og:description" content="This lab will take a look at regularization models and hyperparameter tuning. These models are related to the models we saw in chapter 3 and 4, with the difference that they contain a...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Linear Model Selection and Regularization | ISLR tidymodels Labs">
<meta name="twitter:description" content="This lab will take a look at regularization models and hyperparameter tuning. These models are related to the models we saw in chapter 3 and 4, with the difference that they contain a...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">ISLR tidymodels Labs</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="statistical-learning.html"><span class="header-section-number">2</span> Statistical learning</a></li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">3</span> Linear Regression</a></li>
<li><a class="" href="classification.html"><span class="header-section-number">4</span> Classification</a></li>
<li><a class="" href="resampling-methods.html"><span class="header-section-number">5</span> Resampling Methods</a></li>
<li><a class="active" href="linear-model-selection-and-regularization.html"><span class="header-section-number">6</span> Linear Model Selection and Regularization</a></li>
<li><a class="" href="moving-beyond-linearity.html"><span class="header-section-number">7</span> Moving Beyond Linearity</a></li>
<li><a class="" href="tree-based-methods.html"><span class="header-section-number">8</span> Tree-Based Methods</a></li>
<li><a class="" href="support-vector-machines.html"><span class="header-section-number">9</span> Support Vector Machines</a></li>
<li><a class="" href="deep-learning.html"><span class="header-section-number">10</span> Deep learning</a></li>
<li><a class="" href="survival-analysis-and-censored-data.html"><span class="header-section-number">11</span> Survival Analysis and Censored Data</a></li>
<li><a class="" href="unsupervised-learning.html"><span class="header-section-number">12</span> Unsupervised Learning</a></li>
<li><a class="" href="multiple-testing.html"><span class="header-section-number">13</span> Multiple Testing</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="linear-model-selection-and-regularization" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Linear Model Selection and Regularization<a class="anchor" aria-label="anchor" href="#linear-model-selection-and-regularization"><i class="fas fa-link"></i></a>
</h1>
<p>This lab will take a look at regularization models and hyperparameter tuning. These models are related to the models we saw in chapter 3 and 4, with the difference that they contain a regularization term.
This chapter will use <a href="https://www.tidymodels.org/start/models/">parsnip</a> for model fitting and <a href="https://www.tidymodels.org/start/recipes/">recipes and workflows</a> to perform the transformations, and <a href="https://www.tidymodels.org/start/tuning/">tune and dials</a> to tune the hyperparameters of the model.</p>
<p>We will be using the <code>Hitters</code> data set from the <code>ISLR</code> package. We wish to predict the baseball players <code>Salary</code> based on several different characteristics which are included in the data set. Since we wish to predict <code>Salary</code>, then we need to remove any missing data from that column. Otherwise, we won’t be able to run the models.</p>
<div class="sourceCode" id="cb186"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.statlearning.com">ISLR</a></span><span class="op">)</span>

<span class="va">Hitters</span> <span class="op">&lt;-</span> <span class="fu">as_tibble</span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">Salary</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div id="best-subset-selection" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Best Subset Selection<a class="anchor" aria-label="anchor" href="#best-subset-selection"><i class="fas fa-link"></i></a>
</h2>
<p>tidymodels does not currently support subset selection methods, and it unlikely to include it in the <a href="https://stackoverflow.com/questions/66651033/stepwise-algorithm-in-tidymodels#comment117845482_66651033">near future</a>.</p>
</div>
<div id="forward-and-backward-stepwise-selection" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Forward and Backward Stepwise Selection<a class="anchor" aria-label="anchor" href="#forward-and-backward-stepwise-selection"><i class="fas fa-link"></i></a>
</h2>
<p>tidymodels does not currently support forward and backward stepwise selection methods, and it unlikely to include it in the <a href="https://stackoverflow.com/questions/66651033/stepwise-algorithm-in-tidymodels#comment117845482_66651033">near future</a>.</p>
</div>
<div id="ridge-regression" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Ridge Regression<a class="anchor" aria-label="anchor" href="#ridge-regression"><i class="fas fa-link"></i></a>
</h2>
<p>We will use the <code>glmnet</code> package to perform ridge regression. <code>parsnip</code> does not have a dedicated function to create a ridge regression model specification. You need to use <code>linear_reg()</code> and set <code>mixture = 0</code> to specify a ridge model. The <code>mixture</code> argument specifies the amount of different types of regularization, <code>mixture = 0</code> specifies only ridge regularization and <code>mixture = 1</code> specifies only lasso regularization. Setting <code>mixture</code> to a value between 0 and 1 lets us use both. When using the <code>glmnet</code> engine we also need to set a <code>penalty</code> to be able to fit the model. We will set this value to <code>0</code> for now, it is not the best value, but we will look at how to select the best value in a little bit.</p>
<div class="sourceCode" id="cb187"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_spec</span> <span class="op">&lt;-</span> <span class="fu">linear_reg</span><span class="op">(</span>mixture <span class="op">=</span> <span class="fl">0</span>, penalty <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glmnet"</span><span class="op">)</span></code></pre></div>
<p>Once the specification is created we can fit it to our data. We will use all the predictors.</p>
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_fit</span> <span class="op">&lt;-</span> <span class="fu">fit</span><span class="op">(</span><span class="va">ridge_spec</span>, <span class="va">Salary</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Hitters</span><span class="op">)</span></code></pre></div>
<p>The <code>glmnet</code> package will fit the model for all values of <code>penalty</code> at once, so let us see what the parameter estimate for the model is now that we have <code>penalty = 0</code>.</p>
<div class="sourceCode" id="cb189"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">ridge_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: 'Matrix'</code></pre>
<pre><code>## The following objects are masked from 'package:tidyr':
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 4.1-2</code></pre>
<pre><code>## # A tibble: 20 × 3
##    term          estimate penalty
##    &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;
##  1 (Intercept)   81.1           0
##  2 AtBat         -0.682         0
##  3 Hits           2.77          0
##  4 HmRun         -1.37          0
##  5 Runs           1.01          0
##  6 RBI            0.713         0
##  7 Walks          3.38          0
##  8 Years         -9.07          0
##  9 CAtBat        -0.00120       0
## 10 CHits          0.136         0
## 11 CHmRun         0.698         0
## 12 CRuns          0.296         0
## 13 CRBI           0.257         0
## 14 CWalks        -0.279         0
## 15 LeagueN       53.2           0
## 16 DivisionW   -123.            0
## 17 PutOuts        0.264         0
## 18 Assists        0.170         0
## 19 Errors        -3.69          0
## 20 NewLeagueN   -18.1           0</code></pre>
<p>Let us instead see what the estimates would be if the penalty was 11498.</p>
<div class="sourceCode" id="cb195"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">ridge_fit</span>, penalty <span class="op">=</span> <span class="fl">11498</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 3
##    term         estimate penalty
##    &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;
##  1 (Intercept) 407.        11498
##  2 AtBat         0.0370    11498
##  3 Hits          0.138     11498
##  4 HmRun         0.525     11498
##  5 Runs          0.231     11498
##  6 RBI           0.240     11498
##  7 Walks         0.290     11498
##  8 Years         1.11      11498
##  9 CAtBat        0.00314   11498
## 10 CHits         0.0117    11498
## 11 CHmRun        0.0876    11498
## 12 CRuns         0.0234    11498
## 13 CRBI          0.0242    11498
## 14 CWalks        0.0250    11498
## 15 LeagueN       0.0866    11498
## 16 DivisionW    -6.23      11498
## 17 PutOuts       0.0165    11498
## 18 Assists       0.00262   11498
## 19 Errors       -0.0206    11498
## 20 NewLeagueN    0.303     11498</code></pre>
<p>Notice how the estimates are decreasing when the amount of penalty goes up. Look below at the parameter estimates for <code>penalty = 705</code> and <code>penalty = 50</code>.</p>
<div class="sourceCode" id="cb197"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">ridge_fit</span>, penalty <span class="op">=</span> <span class="fl">705</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 3
##    term        estimate penalty
##    &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;
##  1 (Intercept)  54.4        705
##  2 AtBat         0.112      705
##  3 Hits          0.656      705
##  4 HmRun         1.18       705
##  5 Runs          0.937      705
##  6 RBI           0.847      705
##  7 Walks         1.32       705
##  8 Years         2.58       705
##  9 CAtBat        0.0108     705
## 10 CHits         0.0468     705
## 11 CHmRun        0.338      705
## 12 CRuns         0.0937     705
## 13 CRBI          0.0979     705
## 14 CWalks        0.0718     705
## 15 LeagueN      13.7        705
## 16 DivisionW   -54.7        705
## 17 PutOuts       0.119      705
## 18 Assists       0.0161     705
## 19 Errors       -0.704      705
## 20 NewLeagueN    8.61       705</code></pre>
<div class="sourceCode" id="cb199"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">ridge_fit</span>, penalty <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 3
##    term          estimate penalty
##    &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;
##  1 (Intercept)   48.2          50
##  2 AtBat         -0.354        50
##  3 Hits           1.95         50
##  4 HmRun         -1.29         50
##  5 Runs           1.16         50
##  6 RBI            0.809        50
##  7 Walks          2.71         50
##  8 Years         -6.20         50
##  9 CAtBat         0.00609      50
## 10 CHits          0.107        50
## 11 CHmRun         0.629        50
## 12 CRuns          0.217        50
## 13 CRBI           0.215        50
## 14 CWalks        -0.149        50
## 15 LeagueN       45.9          50
## 16 DivisionW   -118.           50
## 17 PutOuts        0.250        50
## 18 Assists        0.121        50
## 19 Errors        -3.28         50
## 20 NewLeagueN    -9.42         50</code></pre>
<p>We can visualize how the magnitude of the coefficients are being regularized towards zero as the penalty goes up.</p>
<div class="sourceCode" id="cb201"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_fit</span> <span class="op">%&gt;%</span>
  <span class="fu">extract_fit_engine</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>xvar <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-regularization_files/figure-html/unnamed-chunk-7-1.png" width="672"></div>
<p>Prediction is done like normal, if we use <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> by itself, then <code>penalty = 0</code> as we set in the model specification is used.</p>
<div class="sourceCode" id="cb202"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ridge_fit</span>, new_data <span class="op">=</span> <span class="va">Hitters</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 263 × 1
##     .pred
##     &lt;dbl&gt;
##  1  442. 
##  2  676. 
##  3 1059. 
##  4  521. 
##  5  543. 
##  6  218. 
##  7   74.7
##  8   96.1
##  9  809. 
## 10  865. 
## # … with 253 more rows</code></pre>
<p>but we can also get predictions for other values of <code>penalty</code> by specifying it in <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code></p>
<div class="sourceCode" id="cb204"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ridge_fit</span>, new_data <span class="op">=</span> <span class="va">Hitters</span>, penalty <span class="op">=</span> <span class="fl">500</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 263 × 1
##    .pred
##    &lt;dbl&gt;
##  1  525.
##  2  620.
##  3  895.
##  4  425.
##  5  589.
##  6  179.
##  7  147.
##  8  187.
##  9  841.
## 10  840.
## # … with 253 more rows</code></pre>
<p>We saw how we can fit a ridge model and make predictions for different values of <code>penalty</code>. But it would be nice if we could find the “best” value of the penalty. This is something we can use hyperparameter tuning for. Hyperparameter tuning is in its simplest form a way of fitting many models with different sets of hyperparameters trying to find one that performs “best.” The complexity in hyperparameter tuning can come from how you try different models. We will keep it simple for this lab and only look at grid search, only looking at evenly spaced parameter values. This is a fine enough approach if you have one or two tunable parameters but can become computationally infeasible. See the chapter on <a href="https://www.tmwr.org/iterative-search.html">iterative search</a> from <a href="https://www.tmwr.org/">Tidy Modeling with R</a> for more information.</p>
<p>We start like normal by setting up a validation split. A K-fold cross-validation data set is created on the training data set with 10 folds.</p>
<div class="sourceCode" id="cb206"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Hitters_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">Hitters</span>, strata <span class="op">=</span> <span class="st">"Salary"</span><span class="op">)</span>

<span class="va">Hitters_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">Hitters_split</span><span class="op">)</span>
<span class="va">Hitters_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">Hitters_split</span><span class="op">)</span>

<span class="va">Hitters_fold</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">Hitters_train</span>, v <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></code></pre></div>
<p>We can use the <code>tune_grid()</code> function to perform hyperparameter tuning using a grid search. <code>tune_grid()</code> needs 3 different thing;</p>
<ul>
<li>a <code>workflow</code> object containing the model and preprocessor,</li>
<li>a <code>rset</code> object containing the resamples the <code>workflow</code> should be fitted within, and</li>
<li>a tibble containing the parameter values to be evaluated.</li>
</ul>
<p>Optionally a metric set of performance metrics can be supplied for evaluation. If you don’t set one then a default set of performance metrics is used.</p>
<p>We already have a resample object created in <code>Hitters_fold</code>. Now we should create the workflow specification next.</p>
<p>We just used the data set as is when we fit the model earlier. But ridge regression is scale sensitive so we need to make sure that the variables are on the same scale. We can use <code>step_normalize()</code>. Secondly let us deal with the factor variables ourself using <code>step_novel()</code> and <code>step_dummy()</code>.</p>
<div class="sourceCode" id="cb207"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_recipe</span> <span class="op">&lt;-</span> 
  <span class="fu">recipe</span><span class="op">(</span>formula <span class="op">=</span> <span class="va">Salary</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_novel</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_zv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>The model specification will look very similar to what we have seen earlier, but we will set <code>penalty = tune()</code>. This tells <code>tune_grid()</code> that the <code>penalty</code> parameter should be tuned.</p>
<div class="sourceCode" id="cb208"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_spec</span> <span class="op">&lt;-</span> 
  <span class="fu">linear_reg</span><span class="op">(</span>penalty <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, mixture <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glmnet"</span><span class="op">)</span></code></pre></div>
<p>Now we combine to create a <code>workflow</code> object.</p>
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_workflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">ridge_recipe</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">ridge_spec</span><span class="op">)</span></code></pre></div>
<p>The last thing we need is the values of <code>penalty</code> we are trying. This can be created using <code>grid_regular()</code> which creates a grid of evenly spaces parameter values. We use the <code>penalty()</code> function from the <a href="https://dials.tidymodels.org/">dials</a> package to denote the parameter and set the range of the grid we are searching for. Note that this range is log-scaled.</p>
<div class="sourceCode" id="cb210"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penalty_grid</span> <span class="op">&lt;-</span> <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">penalty</span><span class="op">(</span>range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>
<span class="va">penalty_grid</span></code></pre></div>
<pre><code>## # A tibble: 50 × 1
##      penalty
##        &lt;dbl&gt;
##  1 0.00001  
##  2 0.0000160
##  3 0.0000256
##  4 0.0000409
##  5 0.0000655
##  6 0.000105 
##  7 0.000168 
##  8 0.000268 
##  9 0.000429 
## 10 0.000687 
## # … with 40 more rows</code></pre>
<p>Using 50 levels for one parameter might seem overkill and in many applications it is. But remember that <code>glmnet</code> fits all the models in one go so adding more levels to <code>penalty</code> doesn’t affect the computational speed much.</p>
<p>Now we have everything we need and we can fit all the models.</p>
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tune_res</span> <span class="op">&lt;-</span> <span class="fu">tune_grid</span><span class="op">(</span>
  <span class="va">ridge_workflow</span>,
  resamples <span class="op">=</span> <span class="va">Hitters_fold</span>, 
  grid <span class="op">=</span> <span class="va">penalty_grid</span>
<span class="op">)</span>

<span class="va">tune_res</span></code></pre></div>
<pre><code>## # Tuning results
## # 10-fold cross-validation 
## # A tibble: 10 × 4
##    splits           id     .metrics           .notes          
##    &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          
##  1 &lt;split [176/20]&gt; Fold01 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  2 &lt;split [176/20]&gt; Fold02 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  3 &lt;split [176/20]&gt; Fold03 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  4 &lt;split [176/20]&gt; Fold04 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  5 &lt;split [176/20]&gt; Fold05 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  6 &lt;split [176/20]&gt; Fold06 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  7 &lt;split [177/19]&gt; Fold07 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  8 &lt;split [177/19]&gt; Fold08 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  9 &lt;split [177/19]&gt; Fold09 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;
## 10 &lt;split [177/19]&gt; Fold10 &lt;tibble [100 × 5]&gt; &lt;tibble [0 × 1]&gt;</code></pre>
<p>The output of <code>tune_grid()</code> can be hard to read by itself unprocessed. <code>autoplot()</code> creates a great visualization</p>
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">autoplot</span><span class="op">(</span><span class="va">tune_res</span><span class="op">)</span></code></pre></div>
<p><img src="06-regularization_files/figure-html/unnamed-chunk-16-1.png" width="672">
Here we see that the amount of regularization affects the performance metrics differently. Note how there are areas where the amount of regularization doesn’t have any meaningful influence on the coefficient estimates. We can also see the raw metrics that created this chart by calling <code>collect_matrics()</code>.</p>
<div class="sourceCode" id="cb215"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">tune_res</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 100 × 7
##      penalty .metric .estimator    mean     n std_err .config              
##        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
##  1 0.00001   rmse    standard   292.       10 16.2    Preprocessor1_Model01
##  2 0.00001   rsq     standard     0.573    10  0.0558 Preprocessor1_Model01
##  3 0.0000160 rmse    standard   292.       10 16.2    Preprocessor1_Model02
##  4 0.0000160 rsq     standard     0.573    10  0.0558 Preprocessor1_Model02
##  5 0.0000256 rmse    standard   292.       10 16.2    Preprocessor1_Model03
##  6 0.0000256 rsq     standard     0.573    10  0.0558 Preprocessor1_Model03
##  7 0.0000409 rmse    standard   292.       10 16.2    Preprocessor1_Model04
##  8 0.0000409 rsq     standard     0.573    10  0.0558 Preprocessor1_Model04
##  9 0.0000655 rmse    standard   292.       10 16.2    Preprocessor1_Model05
## 10 0.0000655 rsq     standard     0.573    10  0.0558 Preprocessor1_Model05
## # … with 90 more rows</code></pre>
<p>The “best” values of this can be selected using <code>select_best()</code>, this function requires you to specify a <code>matric</code> that it should select against.</p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_penalty</span> <span class="op">&lt;-</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_res</span>, metric <span class="op">=</span> <span class="st">"rsq"</span><span class="op">)</span>
<span class="va">best_penalty</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##   penalty .config              
##     &lt;dbl&gt; &lt;chr&gt;                
## 1 0.00001 Preprocessor1_Model01</code></pre>
<p>This value of <code>penalty</code> can then be used with <code>finalize_workflow()</code> to update/finalize the recipe by replacing <code>tune()</code> with the value of <code>best_penalty</code>. Now, this model should be fit again, this time using the whole training data set.</p>
<div class="sourceCode" id="cb219"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ridge_final</span> <span class="op">&lt;-</span> <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">ridge_workflow</span>, <span class="va">best_penalty</span><span class="op">)</span>

<span class="va">ridge_final_fit</span> <span class="op">&lt;-</span> <span class="fu">fit</span><span class="op">(</span><span class="va">ridge_final</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span></code></pre></div>
<p>This final model can now be applied on our testing data set to validate the performance</p>
<div class="sourceCode" id="cb220"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">augment</span><span class="op">(</span><span class="va">ridge_final_fit</span>, new_data <span class="op">=</span> <span class="va">Hitters_test</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">rsq</span><span class="op">(</span>truth <span class="op">=</span> <span class="va">Salary</span>, estimate <span class="op">=</span> <span class="va">.pred</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rsq     standard       0.175</code></pre>
<p>And it performs fairly well given what we saw earlier.</p>
</div>
<div id="the-lasso" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> The Lasso<a class="anchor" aria-label="anchor" href="#the-lasso"><i class="fas fa-link"></i></a>
</h2>
<p>We will use the <code>glmnet</code> package to perform lasso regression. <code>parsnip</code> does not have a dedicated function to create a ridge regression model specification. You need to use <code>linear_reg()</code> and set <code>mixture = 1</code> to specify a lasso model. The <code>mixture</code> argument specifies the amount of different types of regularization, <code>mixture = 0</code> specifies only ridge regularization and <code>mixture = 1</code> specifies only lasso regularization. Setting <code>mixture</code> to a value between 0 and 1 lets us use both.</p>
<p>The following procedure will be very similar to what we saw in the ridge regression section. The preprocessing needed is the same, but let us write it out one more time.</p>
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lasso_recipe</span> <span class="op">&lt;-</span> 
  <span class="fu">recipe</span><span class="op">(</span>formula <span class="op">=</span> <span class="va">Salary</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_novel</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_zv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Next, we finish the lasso regression <code>workflow</code>.</p>
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lasso_spec</span> <span class="op">&lt;-</span> 
  <span class="fu">linear_reg</span><span class="op">(</span>penalty <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, mixture <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glmnet"</span><span class="op">)</span> 

<span class="va">lasso_workflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">lasso_recipe</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lasso_spec</span><span class="op">)</span></code></pre></div>
<p>While we are doing a different kind of regularization we still use the same <code>penalty</code> argument. I have picked a different range for the values of penalty since I know it will be a good range. You would in practice have to cast a wide net at first and then narrow on the range of interest.</p>
<div class="sourceCode" id="cb224"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penalty_grid</span> <span class="op">&lt;-</span> <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">penalty</span><span class="op">(</span>range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></code></pre></div>
<p>And we can use <code>tune_grid()</code> again.</p>
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tune_res</span> <span class="op">&lt;-</span> <span class="fu">tune_grid</span><span class="op">(</span>
  <span class="va">lasso_workflow</span>,
  resamples <span class="op">=</span> <span class="va">Hitters_fold</span>, 
  grid <span class="op">=</span> <span class="va">penalty_grid</span>
<span class="op">)</span>

<span class="fu">autoplot</span><span class="op">(</span><span class="va">tune_res</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-regularization_files/figure-html/unnamed-chunk-24-1.png" width="672"></div>
<p>We select the best value of <code>penalty</code> using <code>select_best()</code></p>
<div class="sourceCode" id="cb226"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_penalty</span> <span class="op">&lt;-</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_res</span>, metric <span class="op">=</span> <span class="st">"rsq"</span><span class="op">)</span></code></pre></div>
<p>And refit the using the whole training data set.</p>
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lasso_final</span> <span class="op">&lt;-</span> <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">lasso_workflow</span>, <span class="va">best_penalty</span><span class="op">)</span>

<span class="va">lasso_final_fit</span> <span class="op">&lt;-</span> <span class="fu">fit</span><span class="op">(</span><span class="va">lasso_final</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span></code></pre></div>
<p>And we are done, by calculating the <code>rsq</code> value for the lasso model can we see that for this data it doesn’t make much difference which kind of regularization we use as they have similar performance.</p>
<div class="sourceCode" id="cb228"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">augment</span><span class="op">(</span><span class="va">ridge_final_fit</span>, new_data <span class="op">=</span> <span class="va">Hitters_test</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">rsq</span><span class="op">(</span>truth <span class="op">=</span> <span class="va">Salary</span>, estimate <span class="op">=</span> <span class="va">.pred</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rsq     standard       0.175</code></pre>
</div>
<div id="principal-components-regression" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> Principal Components Regression<a class="anchor" aria-label="anchor" href="#principal-components-regression"><i class="fas fa-link"></i></a>
</h2>
<p>We will talk more about principal components analysis in chapter 10. This section will show how principal components can be used as a dimensionality reduction preprocessing step.</p>
<p>I will treat principal component regression as a linear model with PCA transformations in the preprocessing. But using the tidymodels framework then this is still mostly one model.</p>
<div class="sourceCode" id="cb230"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_spec</span> <span class="op">&lt;-</span> 
  <span class="fu">linear_reg</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"lm"</span><span class="op">)</span></code></pre></div>
<p>The preprocessing recipe will closely resemble the recipe we saw in the ridge and lasso sections. The main difference is that we end the recipe with <code>step_pca()</code> which will perform principal component analysis on all the predictors, and return the components that explain <code>threshold</code> percent of the variance. We have set <code>threshold = tune()</code> so we can treat the threshold as a hyperparameter to be tuned. By using workflows and tune together can be tune parameters in the preprocessing as well as parameters in the models.</p>
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pca_recipe</span> <span class="op">&lt;-</span> 
  <span class="fu">recipe</span><span class="op">(</span>formula <span class="op">=</span> <span class="va">Salary</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_novel</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_zv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_pca</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span>, threshold <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="va">pca_workflow</span> <span class="op">&lt;-</span> 
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">pca_recipe</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lm_spec</span><span class="op">)</span></code></pre></div>
<p>We create a smaller grid for <code>threshold</code> and we don’t need to modify the range since <code>[0, 1]</code> is an acceptable range.</p>
<div class="sourceCode" id="cb232"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">threshold_grid</span> <span class="op">&lt;-</span> <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">threshold</span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>
<span class="va">threshold_grid</span></code></pre></div>
<pre><code>## # A tibble: 10 × 1
##    threshold
##        &lt;dbl&gt;
##  1     0    
##  2     0.111
##  3     0.222
##  4     0.333
##  5     0.444
##  6     0.556
##  7     0.667
##  8     0.778
##  9     0.889
## 10     1</code></pre>
<p>And now we fit using <code>tune_grid()</code>. This time we will actually perform 100 fits since we need to fit a model for each value of <code>threshold</code> within each fold.</p>
<div class="sourceCode" id="cb234"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tune_res</span> <span class="op">&lt;-</span> <span class="fu">tune_grid</span><span class="op">(</span>
  <span class="va">pca_workflow</span>,
  resamples <span class="op">=</span> <span class="va">Hitters_fold</span>, 
  grid <span class="op">=</span> <span class="va">threshold_grid</span>
<span class="op">)</span></code></pre></div>
<p>The results look a little shaky here.</p>
<div class="sourceCode" id="cb235"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">autoplot</span><span class="op">(</span><span class="va">tune_res</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-regularization_files/figure-html/unnamed-chunk-32-1.png" width="672"></div>
<p>But we can still select the best model.</p>
<div class="sourceCode" id="cb236"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_threshold</span> <span class="op">&lt;-</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_res</span>, metric <span class="op">=</span> <span class="st">"rmse"</span><span class="op">)</span></code></pre></div>
<p>And fit the model much like have done a couple of times by now. The workflow is finalized using the value we selected with <code>select_best()</code>, and training using the full training data set.</p>
<div class="sourceCode" id="cb237"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pca_final</span> <span class="op">&lt;-</span> <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">pca_workflow</span>, <span class="va">best_threshold</span><span class="op">)</span>

<span class="va">pca_final_fit</span> <span class="op">&lt;-</span> <span class="fu">fit</span><span class="op">(</span><span class="va">pca_final</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span></code></pre></div>
</div>
<div id="partial-least-squares" class="section level2" number="6.6">
<h2>
<span class="header-section-number">6.6</span> Partial Least Squares<a class="anchor" aria-label="anchor" href="#partial-least-squares"><i class="fas fa-link"></i></a>
</h2>
<p>Lastly, we have a partial least squares model. We will treat this much like the PCA section and say that partial least squares calculations will be done as a preprocessing that we tune. The following code is almost identical to previous chapters and will be shown in full without many explanations to avoid repetition. If you skipped to this section, go back and read the previous sections for more commentary.</p>
<div class="sourceCode" id="cb238"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pls_recipe</span> <span class="op">&lt;-</span> 
  <span class="fu">recipe</span><span class="op">(</span>formula <span class="op">=</span> <span class="va">Salary</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_novel</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_zv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_pls</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span>, num_comp <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, outcome <span class="op">=</span> <span class="st">"Salary"</span><span class="op">)</span>

<span class="va">lm_spec</span> <span class="op">&lt;-</span> <span class="fu">linear_reg</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"lm"</span><span class="op">)</span> 

<span class="va">pls_workflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">pls_recipe</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lm_spec</span><span class="op">)</span> 

<span class="va">num_comp_grid</span> <span class="op">&lt;-</span> <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">num_comp</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>

<span class="va">tune_res</span> <span class="op">&lt;-</span> <span class="fu">tune_grid</span><span class="op">(</span>
  <span class="va">pls_workflow</span>,
  resamples <span class="op">=</span> <span class="va">Hitters_fold</span>, 
  grid <span class="op">=</span> <span class="va">num_comp_grid</span>
<span class="op">)</span>

<span class="va">best_threshold</span> <span class="op">&lt;-</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_res</span>, metric <span class="op">=</span> <span class="st">"rmse"</span><span class="op">)</span>

<span class="va">pls_final</span> <span class="op">&lt;-</span> <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">pls_workflow</span>, <span class="va">best_threshold</span><span class="op">)</span>

<span class="va">pls_final_fit</span> <span class="op">&lt;-</span> <span class="fu">fit</span><span class="op">(</span><span class="va">pls_final</span>, data <span class="op">=</span> <span class="va">Hitters_train</span><span class="op">)</span></code></pre></div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="resampling-methods.html"><span class="header-section-number">5</span> Resampling Methods</a></div>
<div class="next"><a href="moving-beyond-linearity.html"><span class="header-section-number">7</span> Moving Beyond Linearity</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-model-selection-and-regularization"><span class="header-section-number">6</span> Linear Model Selection and Regularization</a></li>
<li><a class="nav-link" href="#best-subset-selection"><span class="header-section-number">6.1</span> Best Subset Selection</a></li>
<li><a class="nav-link" href="#forward-and-backward-stepwise-selection"><span class="header-section-number">6.2</span> Forward and Backward Stepwise Selection</a></li>
<li><a class="nav-link" href="#ridge-regression"><span class="header-section-number">6.3</span> Ridge Regression</a></li>
<li><a class="nav-link" href="#the-lasso"><span class="header-section-number">6.4</span> The Lasso</a></li>
<li><a class="nav-link" href="#principal-components-regression"><span class="header-section-number">6.5</span> Principal Components Regression</a></li>
<li><a class="nav-link" href="#partial-least-squares"><span class="header-section-number">6.6</span> Partial Least Squares</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>ISLR tidymodels Labs</strong>" was written by Emil Hvitfeldt. It was last built on 2021-10-19.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
