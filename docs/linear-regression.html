<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Linear Regression | ISLR tidymodels Labs</title>
<meta name="author" content="Emil Hvitfeldt">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.7.12/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4.9002/tabs.js"></script><script src="libs/bs3compat-0.2.4.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">ISLR tidymodels Labs</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="statististical-learning.html"><span class="header-section-number">2</span> Statististical learning</a></li>
<li><a class="active" href="linear-regression.html"><span class="header-section-number">3</span> Linear Regression</a></li>
<li><a class="" href="classification.html"><span class="header-section-number">4</span> Classification</a></li>
<li><a class="" href="resampling-methods.html"><span class="header-section-number">5</span> Resampling Methods</a></li>
<li><a class="" href="linear-model-selection-and-regularization.html"><span class="header-section-number">6</span> Linear Model Selection and Regularization</a></li>
<li><a class="" href="moving-beyond-linearity.html"><span class="header-section-number">7</span> Moving Beyond Linearity</a></li>
<li><a class="" href="tree-based-methods.html"><span class="header-section-number">8</span> Tree-Based Methods</a></li>
<li><a class="" href="support-vector-machines.html"><span class="header-section-number">9</span> Support Vector Machines</a></li>
<li><a class="" href="unsupervised-learning.html"><span class="header-section-number">10</span> Unsupervised Learning</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="linear-regression" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Linear Regression<a class="anchor" aria-label="anchor" href="#linear-regression"><i class="fas fa-link"></i></a>
</h1>
<p>This lab will go over how to perform linear regression. This will include <a href="linear-regression.html#simple-linear-regression">simple linear regression</a> and <a href="linear-regression.html#multiple-linear-regression">multiple linear regression</a> in addition to how you can apply transformations to the predictors. This chapter will use <a href="https://www.tidymodels.org/start/models/">parsnip</a> for model fitting and <a href="https://www.tidymodels.org/start/recipes/">recipes and workflows</a> to perform the transformations.</p>
<div id="libraries" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Libraries<a class="anchor" aria-label="anchor" href="#libraries"><i class="fas fa-link"></i></a>
</h2>
<p>We load tidymodels and ISLR and MASS for data sets.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span> <span class="co"># For Boston data set</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.StatLearning.com">ISLR</a></span><span class="op">)</span></code></pre></div>
</div>
<div id="simple-linear-regression" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Simple linear regression<a class="anchor" aria-label="anchor" href="#simple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>The <code>Boston</code> data set contain various statistics for 506 neighborhoods in Boston. We will build a simple linear regression model that related the median value of owner-occupied homes (<code>medv</code>) as the response with a variable indicating the percentage of the population that belongs to a lower status (<code>lstat</code>) as the predictor.</p>
<div class="infobox">
<p>
The <code>Boston</code> data set is quite outdated and contains some really unfortunate variables.
</p>
</div>
<p>We start by creating a parsnip specification for a linear regression model.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_spec</span> <span class="op">&lt;-</span> <span class="fu">linear_reg</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"lm"</span><span class="op">)</span></code></pre></div>
<p>While it is unnecessary to set the mode for a linear regression since it can only be regression, we continue to do it in these labs to be explicit.</p>
<p>The specification doesn’t perform any calculations by itself. It is just a specification of what we want to do.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_spec</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: lm</code></pre>
<p>Once we have the specification we can <code>fit</code> it by supplying a formula expression and the data we want to fit the model on.
The formula is written on the form <code>y ~ x</code> where <code>y</code> is the name of the response and <code>x</code> is the name of the predictors.
The names used in the formula should match the names of the variables in the data set passed to <code>data</code>.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit</span> <span class="op">&lt;-</span> <span class="va">lm_spec</span> <span class="op">%&gt;%</span>
  <span class="fu">fit</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span>

<span class="va">lm_fit</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  4ms 
## 
## Call:
## stats::lm(formula = medv ~ lstat, data = data)
## 
## Coefficients:
## (Intercept)        lstat  
##       34.55        -0.95</code></pre>
<p>The result of this fit is a parsnip model object. This object contains the underlying fit as well as some parsnip-specific information. If we want to look at the underlying fit object we can access it with <code>lm_fit$fit</code> or with</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit</span> <span class="op">%&gt;%</span> 
  <span class="fu">pluck</span><span class="op">(</span><span class="st">"fit"</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## Call:
## stats::lm(formula = medv ~ lstat, data = data)
## 
## Coefficients:
## (Intercept)        lstat  
##       34.55        -0.95</code></pre>
<p>The <code>lm</code> object has a nice <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> method that shows more information about the fit, including parameter estimates and lack-of-fit statistics.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit</span> <span class="op">%&gt;%</span> 
  <span class="fu">pluck</span><span class="op">(</span><span class="st">"fit"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## Call:
## stats::lm(formula = medv ~ lstat, data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.168  -3.990  -1.318   2.034  24.500 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***
## lstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.216 on 504 degrees of freedom
## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 
## F-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We can use packages from the <a href="https://broom.tidymodels.org/">broom</a> package to extract key information out of the model objects in tidy formats.</p>
<p>the <code>tidy()</code> function returns the parameter estimates of a <code>lm</code> object</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tidy</span><span class="op">(</span><span class="va">lm_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)   34.6      0.563       61.4 3.74e-236
## 2 lstat         -0.950    0.0387     -24.5 5.08e- 88</code></pre>
<p>and <code>glance()</code> can be used to extract the model statistics.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">glance</span><span class="op">(</span><span class="va">lm_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.544         0.543  6.22      602. 5.08e-88     1 -1641. 3289. 3302.
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p>Suppose that we like the model fit and we want to generate predictions, we would typically use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function like so:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lm_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## Error in predict_numeric(object = object, new_data = new_data, ...): argument "new_data" is missing, with no default</code></pre>
<p>But this produces an error when used on a parsnip model object. This is happening because we need to explicitly supply the data set that the predictions should be performed on via the <code>new_data</code> argument</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lm_fit</span>, new_data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 506 x 1
##    .pred
##    &lt;dbl&gt;
##  1 29.8 
##  2 25.9 
##  3 30.7 
##  4 31.8 
##  5 29.5 
##  6 29.6 
##  7 22.7 
##  8 16.4 
##  9  6.12
## 10 18.3 
## # … with 496 more rows</code></pre>
<p>Notice how the predictions are returned as a tibble. This will always be the case for parsnip models, no matter what engine is used. This is very useful since consistency allows us to combine data sets easily.</p>
<p>We can also return other types of predicts by specifying the <code>type</code> argument. Setting <code>type = "conf_int"</code> return a 95% confidence interval.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lm_fit</span>, new_data <span class="op">=</span> <span class="va">Boston</span>, type <span class="op">=</span> <span class="st">"conf_int"</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 506 x 2
##    .pred_lower .pred_upper
##          &lt;dbl&gt;       &lt;dbl&gt;
##  1       29.0        30.6 
##  2       25.3        26.5 
##  3       29.9        31.6 
##  4       30.8        32.7 
##  5       28.7        30.3 
##  6       28.8        30.4 
##  7       22.2        23.3 
##  8       15.6        17.1 
##  9        4.70        7.54
## 10       17.7        18.9 
## # … with 496 more rows</code></pre>
<div class="infobox">
<p>
Not all engines can return all types of predictions.
</p>
</div>
<p>If you want to evaluate the performance of a model, you might want to compare the observed value and the predicted value for a data set. You</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bind_cols</span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lm_fit</span>, new_data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span>,
  <span class="va">Boston</span>
<span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/lm.ridge.html">select</a></span><span class="op">(</span><span class="va">medv</span>, <span class="va">.pred</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 506 x 2
##     medv .pred
##    &lt;dbl&gt; &lt;dbl&gt;
##  1  24   29.8 
##  2  21.6 25.9 
##  3  34.7 30.7 
##  4  33.4 31.8 
##  5  36.2 29.5 
##  6  28.7 29.6 
##  7  22.9 22.7 
##  8  27.1 16.4 
##  9  16.5  6.12
## 10  18.9 18.3 
## # … with 496 more rows</code></pre>
<p>You can get the same results using the <code>augment()</code> function to same you a little bit of typing</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">augment</span><span class="op">(</span><span class="va">lm_fit</span>, new_data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/lm.ridge.html">select</a></span><span class="op">(</span><span class="va">medv</span>, <span class="va">.pred</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 506 x 2
##     medv .pred
##    &lt;dbl&gt; &lt;dbl&gt;
##  1  24   29.8 
##  2  21.6 25.9 
##  3  34.7 30.7 
##  4  33.4 31.8 
##  5  36.2 29.5 
##  6  28.7 29.6 
##  7  22.9 22.7 
##  8  27.1 16.4 
##  9  16.5  6.12
## 10  18.9 18.3 
## # … with 496 more rows</code></pre>
</div>
<div id="multiple-linear-regression" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Multiple linear regression<a class="anchor" aria-label="anchor" href="#multiple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>The multiple linear regression model can be fit in much the same way as the <a href="linear-regression.html#simple-linear-regression">simple linear regression</a> model. The only difference is how we specify the predictors. We are using the same formula expression <code>y ~ x</code>, but we can specify multiple values by separating them with <code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code>s.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit2</span> <span class="op">&lt;-</span> <span class="va">lm_spec</span> <span class="op">%&gt;%</span> 
  <span class="fu">fit</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span> <span class="op">+</span> <span class="va">age</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span>

<span class="va">lm_fit2</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  2ms 
## 
## Call:
## stats::lm(formula = medv ~ lstat + age, data = data)
## 
## Coefficients:
## (Intercept)        lstat          age  
##    33.22276     -1.03207      0.03454</code></pre>
<p>Everything else works the same. From extracting parameter estimates</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tidy</span><span class="op">(</span><span class="va">lm_fit2</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  33.2       0.731      45.5  2.94e-180
## 2 lstat        -1.03      0.0482    -21.4  8.42e- 73
## 3 age           0.0345    0.0122      2.83 4.91e-  3</code></pre>
<p>to predicting new values</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lm_fit2</span>, new_data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 506 x 1
##    .pred
##    &lt;dbl&gt;
##  1 30.3 
##  2 26.5 
##  3 31.2 
##  4 31.8 
##  5 29.6 
##  6 29.9 
##  7 22.7 
##  8 16.8 
##  9  5.79
## 10 18.5 
## # … with 496 more rows</code></pre>
<p>A shortcut when using formulas is to use the form <code>y ~ .</code> which means; set <code>y</code> as the response and set the remaining variables as predictors. This is very useful if you have a lot of variables and you don’t want to type them out.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit3</span> <span class="op">&lt;-</span> <span class="va">lm_spec</span> <span class="op">%&gt;%</span> 
  <span class="fu">fit</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span>

<span class="va">lm_fit3</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  3ms 
## 
## Call:
## stats::lm(formula = medv ~ ., data = data)
## 
## Coefficients:
## (Intercept)         crim           zn        indus         chas          nox  
##   3.646e+01   -1.080e-01    4.642e-02    2.056e-02    2.687e+00   -1.777e+01  
##          rm          age          dis          rad          tax      ptratio  
##   3.810e+00    6.922e-04   -1.476e+00    3.060e-01   -1.233e-02   -9.527e-01  
##       black        lstat  
##   9.312e-03   -5.248e-01</code></pre>
<p>For more formula syntax look at <code><a href="https://rdrr.io/r/stats/formula.html">?formula</a></code>.</p>
</div>
<div id="interaction-terms" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Interaction terms<a class="anchor" aria-label="anchor" href="#interaction-terms"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit</span> <span class="op">&lt;-</span> <span class="va">lm_spec</span> <span class="op">%&gt;%</span>
  <span class="fu">fit</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span> <span class="op">*</span> <span class="va">age</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span>

<span class="va">lm_fit</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  2ms 
## 
## Call:
## stats::lm(formula = medv ~ lstat * age, data = data)
## 
## Coefficients:
## (Intercept)        lstat          age    lstat:age  
##  36.0885359   -1.3921168   -0.0007209    0.0041560</code></pre>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rec_spec</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span> <span class="op">+</span> <span class="va">age</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_interact</span><span class="op">(</span><span class="op">~</span> <span class="va">lstat</span><span class="op">:</span><span class="va">age</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lm_spec</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">rec_spec</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">%&gt;%</span> <span class="fu">fit</span><span class="op">(</span><span class="va">Boston</span><span class="op">)</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: linear_reg()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 1 Recipe Step
## 
## • step_interact()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
## (Intercept)        lstat          age  lstat_x_age  
##  36.0885359   -1.3921168   -0.0007209    0.0041560</code></pre>
</div>
<div id="non-linear-transformations-of-the-predictors" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Non-linear transformations of the predictors<a class="anchor" aria-label="anchor" href="#non-linear-transformations-of-the-predictors"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_fit</span> <span class="op">&lt;-</span> <span class="va">lm_spec</span> <span class="op">%&gt;%</span>
  <span class="fu">fit</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">lstat</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span>

<span class="va">lm_fit</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  1ms 
## 
## Call:
## stats::lm(formula = medv ~ lstat + I(lstat^2), data = data)
## 
## Coefficients:
## (Intercept)        lstat   I(lstat^2)  
##    42.86201     -2.33282      0.04355</code></pre>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rec_spec</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_mutate</span><span class="op">(</span>lstat2 <span class="op">=</span> <span class="va">lstat</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lm_spec</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">rec_spec</span><span class="op">)</span>

<span class="va">lm_fit2</span> <span class="op">&lt;-</span> <span class="va">lm_wf</span> <span class="op">%&gt;%</span> <span class="fu">fit</span><span class="op">(</span><span class="va">Boston</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rec_spec</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">lstat</span>, data <span class="op">=</span> <span class="va">Boston</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_log</span><span class="op">(</span><span class="va">lstat</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lm_spec</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">rec_spec</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">%&gt;%</span> <span class="fu">fit</span><span class="op">(</span><span class="va">Boston</span><span class="op">)</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: linear_reg()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 1 Recipe Step
## 
## • step_log()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
## (Intercept)        lstat  
##       52.12       -12.48</code></pre>
</div>
<div id="qualitative-predictors" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Qualitative predictors<a class="anchor" aria-label="anchor" href="#qualitative-predictors"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Carseats</span></code></pre></div>
<pre><code>##     Sales CompPrice Income Advertising Population Price ShelveLoc Age Education
## 1    9.50       138     73          11        276   120       Bad  42        17
## 2   11.22       111     48          16        260    83      Good  65        10
## 3   10.06       113     35          10        269    80    Medium  59        12
## 4    7.40       117    100           4        466    97    Medium  55        14
## 5    4.15       141     64           3        340   128       Bad  38        13
## 6   10.81       124    113          13        501    72       Bad  78        16
## 7    6.63       115    105           0         45   108    Medium  71        15
## 8   11.85       136     81          15        425   120      Good  67        10
## 9    6.54       132    110           0        108   124    Medium  76        10
## 10   4.69       132    113           0        131   124    Medium  76        17
## 11   9.01       121     78           9        150   100       Bad  26        10
## 12  11.96       117     94           4        503    94      Good  50        13
## 13   3.98       122     35           2        393   136    Medium  62        18
## 14  10.96       115     28          11         29    86      Good  53        18
## 15  11.17       107    117          11        148   118      Good  52        18
## 16   8.71       149     95           5        400   144    Medium  76        18
## 17   7.58       118     32           0        284   110      Good  63        13
## 18  12.29       147     74          13        251   131      Good  52        10
## 19  13.91       110    110           0        408    68      Good  46        17
## 20   8.73       129     76          16         58   121    Medium  69        12
## 21   6.41       125     90           2        367   131    Medium  35        18
## 22  12.13       134     29          12        239   109      Good  62        18
## 23   5.08       128     46           6        497   138    Medium  42        13
## 24   5.87       121     31           0        292   109    Medium  79        10
## 25  10.14       145    119          16        294   113       Bad  42        12
## 26  14.90       139     32           0        176    82      Good  54        11
## 27   8.33       107    115          11        496   131      Good  50        11
## 28   5.27        98    118           0         19   107    Medium  64        17
## 29   2.99       103     74           0        359    97       Bad  55        11
## 30   7.81       104     99          15        226   102       Bad  58        17
## 31  13.55       125     94           0        447    89      Good  30        12
## 32   8.25       136     58          16        241   131    Medium  44        18
## 33   6.20       107     32          12        236   137      Good  64        10
## 34   8.77       114     38          13        317   128      Good  50        16
## 35   2.67       115     54           0        406   128    Medium  42        17
## 36  11.07       131     84          11         29    96    Medium  44        17
## 37   8.89       122     76           0        270   100      Good  60        18
## 38   4.95       121     41           5        412   110    Medium  54        10
## 39   6.59       109     73           0        454   102    Medium  65        15
## 40   3.24       130     60           0        144   138       Bad  38        10
## 41   2.07       119     98           0         18   126       Bad  73        17
## 42   7.96       157     53           0        403   124       Bad  58        16
## 43  10.43        77     69           0         25    24    Medium  50        18
## 44   4.12       123     42          11         16   134    Medium  59        13
## 45   4.16        85     79           6        325    95    Medium  69        13
## 46   4.56       141     63           0        168   135       Bad  44        12
## 47  12.44       127     90          14         16    70    Medium  48        15
## 48   4.38       126     98           0        173   108       Bad  55        16
## 49   3.91       116     52           0        349    98       Bad  69        18
## 50  10.61       157     93           0         51   149      Good  32        17
## 51   1.42        99     32          18        341   108       Bad  80        16
## 52   4.42       121     90           0        150   108       Bad  75        16
## 53   7.91       153     40           3        112   129       Bad  39        18
## 54   6.92       109     64          13         39   119    Medium  61        17
## 55   4.90       134    103          13         25   144    Medium  76        17
## 56   6.85       143     81           5         60   154    Medium  61        18
## 57  11.91       133     82           0         54    84    Medium  50        17
## 58   0.91        93     91           0         22   117       Bad  75        11
## 59   5.42       103     93          15        188   103       Bad  74        16
## 60   5.21       118     71           4        148   114    Medium  80        13
## 61   8.32       122    102          19        469   123       Bad  29        13
## 62   7.32       105     32           0        358   107    Medium  26        13
## 63   1.82       139     45           0        146   133       Bad  77        17
## 64   8.47       119     88          10        170   101    Medium  61        13
## 65   7.80       100     67          12        184   104    Medium  32        16
## 66   4.90       122     26           0        197   128    Medium  55        13
## 67   8.85       127     92           0        508    91    Medium  56        18
## 68   9.01       126     61          14        152   115    Medium  47        16
## 69  13.39       149     69          20        366   134      Good  60        13
## 70   7.99       127     59           0        339    99    Medium  65        12
## 71   9.46        89     81          15        237    99      Good  74        12
## 72   6.50       148     51          16        148   150    Medium  58        17
## 73   5.52       115     45           0        432   116    Medium  25        15
## 74  12.61       118     90          10         54   104      Good  31        11
## 75   6.20       150     68           5        125   136    Medium  64        13
## 76   8.55        88    111          23        480    92       Bad  36        16
## 77  10.64       102     87          10        346    70    Medium  64        15
## 78   7.70       118     71          12         44    89    Medium  67        18
## 79   4.43       134     48           1        139   145    Medium  65        12
## 80   9.14       134     67           0        286    90       Bad  41        13
## 81   8.01       113    100          16        353    79       Bad  68        11
## 82   7.52       116     72           0        237   128      Good  70        13
## 83  11.62       151     83           4        325   139      Good  28        17
## 84   4.42       109     36           7        468    94       Bad  56        11
## 85   2.23       111     25           0         52   121       Bad  43        18
## 86   8.47       125    103           0        304   112    Medium  49        13
## 87   8.70       150     84           9        432   134    Medium  64        15
## 88  11.70       131     67           7        272   126      Good  54        16
## 89   6.56       117     42           7        144   111    Medium  62        10
## 90   7.95       128     66           3        493   119    Medium  45        16
## 91   5.33       115     22           0        491   103    Medium  64        11
## 92   4.81        97     46          11        267   107    Medium  80        15
## 93   4.53       114    113           0         97   125    Medium  29        12
## 94   8.86       145     30           0         67   104    Medium  55        17
## 95   8.39       115     97           5        134    84       Bad  55        11
## 96   5.58       134     25          10        237   148    Medium  59        13
## 97   9.48       147     42          10        407   132      Good  73        16
## 98   7.45       161     82           5        287   129       Bad  33        16
## 99  12.49       122     77          24        382   127      Good  36        16
## 100  4.88       121     47           3        220   107       Bad  56        16
## 101  4.11       113     69          11         94   106    Medium  76        12
## 102  6.20       128     93           0         89   118    Medium  34        18
## 103  5.30       113     22           0         57    97    Medium  65        16
## 104  5.07       123     91           0        334    96       Bad  78        17
## 105  4.62       121     96           0        472   138    Medium  51        12
## 106  5.55       104    100           8        398    97    Medium  61        11
## 107  0.16       102     33           0        217   139    Medium  70        18
## 108  8.55       134    107           0        104   108    Medium  60        12
## 109  3.47       107     79           2        488   103       Bad  65        16
## 110  8.98       115     65           0        217    90    Medium  60        17
## 111  9.00       128     62           7        125   116    Medium  43        14
## 112  6.62       132    118          12        272   151    Medium  43        14
## 113  6.67       116     99           5        298   125      Good  62        12
## 114  6.01       131     29          11        335   127       Bad  33        12
## 115  9.31       122     87           9         17   106    Medium  65        13
## 116  8.54       139     35           0         95   129    Medium  42        13
## 117  5.08       135     75           0        202   128    Medium  80        10
## 118  8.80       145     53           0        507   119    Medium  41        12
## 119  7.57       112     88           2        243    99    Medium  62        11
## 120  7.37       130     94           8        137   128    Medium  64        12
## 121  6.87       128    105          11        249   131    Medium  63        13
## 122 11.67       125     89          10        380    87       Bad  28        10
## 123  6.88       119    100           5         45   108    Medium  75        10
## 124  8.19       127    103           0        125   155      Good  29        15
## 125  8.87       131    113           0        181   120      Good  63        14
## 126  9.34        89     78           0        181    49    Medium  43        15
## 127 11.27       153     68           2         60   133      Good  59        16
## 128  6.52       125     48           3        192   116    Medium  51        14
## 129  4.96       133    100           3        350   126       Bad  55        13
## 130  4.47       143    120           7        279   147       Bad  40        10
## 131  8.41        94     84          13        497    77    Medium  51        12
## 132  6.50       108     69           3        208    94    Medium  77        16
## 133  9.54       125     87           9        232   136      Good  72        10
## 134  7.62       132     98           2        265    97       Bad  62        12
## 135  3.67       132     31           0        327   131    Medium  76        16
## 136  6.44        96     94          14        384   120    Medium  36        18
## 137  5.17       131     75           0         10   120       Bad  31        18
## 138  6.52       128     42           0        436   118    Medium  80        11
## 139 10.27       125    103          12        371   109    Medium  44        10
## 140 12.30       146     62          10        310    94    Medium  30        13
## 141  6.03       133     60          10        277   129    Medium  45        18
## 142  6.53       140     42           0        331   131       Bad  28        15
## 143  7.44       124     84           0        300   104    Medium  77        15
## 144  0.53       122     88           7         36   159       Bad  28        17
## 145  9.09       132     68           0        264   123      Good  34        11
## 146  8.77       144     63          11         27   117    Medium  47        17
## 147  3.90       114     83           0        412   131       Bad  39        14
## 148 10.51       140     54           9        402   119      Good  41        16
## 149  7.56       110    119           0        384    97    Medium  72        14
## 150 11.48       121    120          13        140    87    Medium  56        11
## 151 10.49       122     84           8        176   114      Good  57        10
## 152 10.77       111     58          17        407   103      Good  75        17
## 153  7.64       128     78           0        341   128      Good  45        13
## 154  5.93       150     36           7        488   150    Medium  25        17
## 155  6.89       129     69          10        289   110    Medium  50        16
## 156  7.71        98     72           0         59    69    Medium  65        16
## 157  7.49       146     34           0        220   157      Good  51        16
## 158 10.21       121     58           8        249    90    Medium  48        13
## 159 12.53       142     90           1        189   112      Good  39        10
## 160  9.32       119     60           0        372    70       Bad  30        18
## 161  4.67       111     28           0        486   111    Medium  29        12
## 162  2.93       143     21           5         81   160    Medium  67        12
## 163  3.63       122     74           0        424   149    Medium  51        13
## 164  5.68       130     64           0         40   106       Bad  39        17
## 165  8.22       148     64           0         58   141    Medium  27        13
## 166  0.37       147     58           7        100   191       Bad  27        15
## 167  6.71       119     67          17        151   137    Medium  55        11
## 168  6.71       106     73           0        216    93    Medium  60        13
## 169  7.30       129     89           0        425   117    Medium  45        10
## 170 11.48       104     41          15        492    77      Good  73        18
## 171  8.01       128     39          12        356   118    Medium  71        10
## 172 12.49        93    106          12        416    55    Medium  75        15
## 173  9.03       104    102          13        123   110      Good  35        16
## 174  6.38       135     91           5        207   128    Medium  66        18
## 175  0.00       139     24           0        358   185    Medium  79        15
## 176  7.54       115     89           0         38   122    Medium  25        12
## 177  5.61       138    107           9        480   154    Medium  47        11
## 178 10.48       138     72           0        148    94    Medium  27        17
## 179 10.66       104     71          14         89    81    Medium  25        14
## 180  7.78       144     25           3         70   116    Medium  77        18
## 181  4.94       137    112          15        434   149       Bad  66        13
## 182  7.43       121     83           0         79    91    Medium  68        11
## 183  4.74       137     60           4        230   140       Bad  25        13
## 184  5.32       118     74           6        426   102    Medium  80        18
## 185  9.95       132     33           7         35    97    Medium  60        11
## 186 10.07       130    100          11        449   107    Medium  64        10
## 187  8.68       120     51           0         93    86    Medium  46        17
## 188  6.03       117     32           0        142    96       Bad  62        17
## 189  8.07       116     37           0        426    90    Medium  76        15
## 190 12.11       118    117          18        509   104    Medium  26        15
## 191  8.79       130     37          13        297   101    Medium  37        13
## 192  6.67       156     42          13        170   173      Good  74        14
## 193  7.56       108     26           0        408    93    Medium  56        14
## 194 13.28       139     70           7         71    96      Good  61        10
## 195  7.23       112     98          18        481   128    Medium  45        11
## 196  4.19       117     93           4        420   112       Bad  66        11
## 197  4.10       130     28           6        410   133       Bad  72        16
## 198  2.52       124     61           0        333   138    Medium  76        16
## 199  3.62       112     80           5        500   128    Medium  69        10
## 200  6.42       122     88           5        335   126    Medium  64        14
## 201  5.56       144     92           0        349   146    Medium  62        12
## 202  5.94       138     83           0        139   134    Medium  54        18
## 203  4.10       121     78           4        413   130       Bad  46        10
## 204  2.05       131     82           0        132   157       Bad  25        14
## 205  8.74       155     80           0        237   124    Medium  37        14
## 206  5.68       113     22           1        317   132    Medium  28        12
## 207  4.97       162     67           0         27   160    Medium  77        17
## 208  8.19       111    105           0        466    97       Bad  61        10
## 209  7.78        86     54           0        497    64       Bad  33        12
## 210  3.02        98     21          11        326    90       Bad  76        11
## 211  4.36       125     41           2        357   123       Bad  47        14
## 212  9.39       117    118          14        445   120    Medium  32        15
## 213 12.04       145     69          19        501   105    Medium  45        11
## 214  8.23       149     84           5        220   139    Medium  33        10
## 215  4.83       115    115           3         48   107    Medium  73        18
## 216  2.34       116     83          15        170   144       Bad  71        11
## 217  5.73       141     33           0        243   144    Medium  34        17
## 218  4.34       106     44           0        481   111    Medium  70        14
## 219  9.70       138     61          12        156   120    Medium  25        14
## 220 10.62       116     79          19        359   116      Good  58        17
## 221 10.59       131    120          15        262   124    Medium  30        10
## 222  6.43       124     44           0        125   107    Medium  80        11
## 223  7.49       136    119           6        178   145    Medium  35        13
## 224  3.45       110     45           9        276   125    Medium  62        14
## 225  4.10       134     82           0        464   141    Medium  48        13
## 226  6.68       107     25           0        412    82       Bad  36        14
## 227  7.80       119     33           0        245   122      Good  56        14
## 228  8.69       113     64          10         68   101    Medium  57        16
## 229  5.40       149     73          13        381   163       Bad  26        11
## 230 11.19        98    104           0        404    72    Medium  27        18
## 231  5.16       115     60           0        119   114       Bad  38        14
## 232  8.09       132     69           0        123   122    Medium  27        11
## 233 13.14       137     80          10         24   105      Good  61        15
## 234  8.65       123     76          18        218   120    Medium  29        14
## 235  9.43       115     62          11        289   129      Good  56        16
## 236  5.53       126     32           8         95   132    Medium  50        17
## 237  9.32       141     34          16        361   108    Medium  69        10
## 238  9.62       151     28           8        499   135    Medium  48        10
## 239  7.36       121     24           0        200   133      Good  73        13
## 240  3.89       123    105           0        149   118       Bad  62        16
## 241 10.31       159     80           0        362   121    Medium  26        18
## 242 12.01       136     63           0        160    94    Medium  38        12
## 243  4.68       124     46           0        199   135    Medium  52        14
## 244  7.82       124     25          13         87   110    Medium  57        10
## 245  8.78       130     30           0        391   100    Medium  26        18
## 246 10.00       114     43           0        199    88      Good  57        10
## 247  6.90       120     56          20        266    90       Bad  78        18
## 248  5.04       123    114           0        298   151       Bad  34        16
## 249  5.36       111     52           0         12   101    Medium  61        11
## 250  5.05       125     67           0         86   117       Bad  65        11
## 251  9.16       137    105          10        435   156      Good  72        14
## 252  3.72       139    111           5        310   132       Bad  62        13
## 253  8.31       133     97           0         70   117    Medium  32        16
## 254  5.64       124     24           5        288   122    Medium  57        12
## 255  9.58       108    104          23        353   129      Good  37        17
## 256  7.71       123     81           8        198    81       Bad  80        15
## 257  4.20       147     40           0        277   144    Medium  73        10
## 258  8.67       125     62          14        477   112    Medium  80        13
## 259  3.47       108     38           0        251    81       Bad  72        14
## 260  5.12       123     36          10        467   100       Bad  74        11
## 261  7.67       129    117           8        400   101       Bad  36        10
## 262  5.71       121     42           4        188   118    Medium  54        15
## 263  6.37       120     77          15         86   132    Medium  48        18
## 264  7.77       116     26           6        434   115    Medium  25        17
## 265  6.95       128     29           5        324   159      Good  31        15
## 266  5.31       130     35          10        402   129       Bad  39        17
## 267  9.10       128     93          12        343   112      Good  73        17
## 268  5.83       134     82           7        473   112       Bad  51        12
## 269  6.53       123     57           0         66   105    Medium  39        11
## 270  5.01       159     69           0        438   166    Medium  46        17
## 271 11.99       119     26           0        284    89      Good  26        10
## 272  4.55       111     56           0        504   110    Medium  62        16
## 273 12.98       113     33           0         14    63      Good  38        12
## 274 10.04       116    106           8        244    86    Medium  58        12
## 275  7.22       135     93           2         67   119    Medium  34        11
## 276  6.67       107    119          11        210   132    Medium  53        11
## 277  6.93       135     69          14        296   130    Medium  73        15
## 278  7.80       136     48          12        326   125    Medium  36        16
## 279  7.22       114    113           2        129   151      Good  40        15
## 280  3.42       141     57          13        376   158    Medium  64        18
## 281  2.86       121     86          10        496   145       Bad  51        10
## 282 11.19       122     69           7        303   105      Good  45        16
## 283  7.74       150     96           0         80   154      Good  61        11
## 284  5.36       135    110           0        112   117    Medium  80        16
## 285  6.97       106     46          11        414    96       Bad  79        17
## 286  7.60       146     26          11        261   131    Medium  39        10
## 287  7.53       117    118          11        429   113    Medium  67        18
## 288  6.88        95     44           4        208    72       Bad  44        17
## 289  6.98       116     40           0         74    97    Medium  76        15
## 290  8.75       143     77          25        448   156    Medium  43        17
## 291  9.49       107    111          14        400   103    Medium  41        11
## 292  6.64       118     70           0        106    89       Bad  39        17
## 293 11.82       113     66          16        322    74      Good  76        15
## 294 11.28       123     84           0         74    89      Good  59        10
## 295 12.66       148     76           3        126    99      Good  60        11
## 296  4.21       118     35          14        502   137    Medium  79        10
## 297  8.21       127     44          13        160   123      Good  63        18
## 298  3.07       118     83          13        276   104       Bad  75        10
## 299 10.98       148     63           0        312   130      Good  63        15
## 300  9.40       135     40          17        497    96    Medium  54        17
## 301  8.57       116     78           1        158    99    Medium  45        11
## 302  7.41        99     93           0        198    87    Medium  57        16
## 303  5.28       108     77          13        388   110       Bad  74        14
## 304 10.01       133     52          16        290    99    Medium  43        11
## 305 11.93       123     98          12        408   134      Good  29        10
## 306  8.03       115     29          26        394   132    Medium  33        13
## 307  4.78       131     32           1         85   133    Medium  48        12
## 308  5.90       138     92           0         13   120       Bad  61        12
## 309  9.24       126     80          19        436   126    Medium  52        10
## 310 11.18       131    111          13         33    80       Bad  68        18
## 311  9.53       175     65          29        419   166    Medium  53        12
## 312  6.15       146     68          12        328   132       Bad  51        14
## 313  6.80       137    117           5        337   135       Bad  38        10
## 314  9.33       103     81           3        491    54    Medium  66        13
## 315  7.72       133     33          10        333   129      Good  71        14
## 316  6.39       131     21           8        220   171      Good  29        14
## 317 15.63       122     36           5        369    72      Good  35        10
## 318  6.41       142     30           0        472   136      Good  80        15
## 319 10.08       116     72          10        456   130      Good  41        14
## 320  6.97       127     45          19        459   129    Medium  57        11
## 321  5.86       136     70          12        171   152    Medium  44        18
## 322  7.52       123     39           5        499    98    Medium  34        15
## 323  9.16       140     50          10        300   139      Good  60        15
## 324 10.36       107    105          18        428   103    Medium  34        12
## 325  2.66       136     65           4        133   150       Bad  53        13
## 326 11.70       144     69          11        131   104    Medium  47        11
## 327  4.69       133     30           0        152   122    Medium  53        17
## 328  6.23       112     38          17        316   104    Medium  80        16
## 329  3.15       117     66           1         65   111       Bad  55        11
## 330 11.27       100     54           9        433    89      Good  45        12
## 331  4.99       122     59           0        501   112       Bad  32        14
## 332 10.10       135     63          15        213   134    Medium  32        10
## 333  5.74       106     33          20        354   104    Medium  61        12
## 334  5.87       136     60           7        303   147    Medium  41        10
## 335  7.63        93    117           9        489    83       Bad  42        13
## 336  6.18       120     70          15        464   110    Medium  72        15
## 337  5.17       138     35           6         60   143       Bad  28        18
## 338  8.61       130     38           0        283   102    Medium  80        15
## 339  5.97       112     24           0        164   101    Medium  45        11
## 340 11.54       134     44           4        219   126      Good  44        15
## 341  7.50       140     29           0        105    91       Bad  43        16
## 342  7.38        98    120           0        268    93    Medium  72        10
## 343  7.81       137    102          13        422   118    Medium  71        10
## 344  5.99       117     42          10        371   121       Bad  26        14
## 345  8.43       138     80           0        108   126      Good  70        13
## 346  4.81       121     68           0        279   149      Good  79        12
## 347  8.97       132    107           0        144   125    Medium  33        13
## 348  6.88        96     39           0        161   112      Good  27        14
## 349 12.57       132    102          20        459   107      Good  49        11
## 350  9.32       134     27          18        467    96    Medium  49        14
## 351  8.64       111    101          17        266    91    Medium  63        17
## 352 10.44       124    115          16        458   105    Medium  62        16
## 353 13.44       133    103          14        288   122      Good  61        17
## 354  9.45       107     67          12        430    92    Medium  35        12
## 355  5.30       133     31           1         80   145    Medium  42        18
## 356  7.02       130    100           0        306   146      Good  42        11
## 357  3.58       142    109           0        111   164      Good  72        12
## 358 13.36       103     73           3        276    72    Medium  34        15
## 359  4.17       123     96          10         71   118       Bad  69        11
## 360  3.13       130     62          11        396   130       Bad  66        14
## 361  8.77       118     86           7        265   114      Good  52        15
## 362  8.68       131     25          10        183   104    Medium  56        15
## 363  5.25       131     55           0         26   110       Bad  79        12
## 364 10.26       111     75           1        377   108      Good  25        12
## 365 10.50       122     21          16        488   131      Good  30        14
## 366  6.53       154     30           0        122   162    Medium  57        17
## 367  5.98       124     56          11        447   134    Medium  53        12
## 368 14.37        95    106           0        256    53      Good  52        17
## 369 10.71       109     22          10        348    79      Good  74        14
## 370 10.26       135    100          22        463   122    Medium  36        14
## 371  7.68       126     41          22        403   119       Bad  42        12
## 372  9.08       152     81           0        191   126    Medium  54        16
## 373  7.80       121     50           0        508    98    Medium  65        11
## 374  5.58       137     71           0        402   116    Medium  78        17
## 375  9.44       131     47           7         90   118    Medium  47        12
## 376  7.90       132     46           4        206   124    Medium  73        11
## 377 16.27       141     60          19        319    92      Good  44        11
## 378  6.81       132     61           0        263   125    Medium  41        12
## 379  6.11       133     88           3        105   119    Medium  79        12
## 380  5.81       125    111           0        404   107       Bad  54        15
## 381  9.64       106     64          10         17    89    Medium  68        17
## 382  3.90       124     65          21        496   151       Bad  77        13
## 383  4.95       121     28          19        315   121    Medium  66        14
## 384  9.35        98    117           0         76    68    Medium  63        10
## 385 12.85       123     37          15        348   112      Good  28        12
## 386  5.87       131     73          13        455   132    Medium  62        17
## 387  5.32       152    116           0        170   160    Medium  39        16
## 388  8.67       142     73          14        238   115    Medium  73        14
## 389  8.14       135     89          11        245    78       Bad  79        16
## 390  8.44       128     42           8        328   107    Medium  35        12
## 391  5.47       108     75           9         61   111    Medium  67        12
## 392  6.10       153     63           0         49   124       Bad  56        16
## 393  4.53       129     42          13        315   130       Bad  34        13
## 394  5.57       109     51          10         26   120    Medium  30        17
## 395  5.35       130     58          19        366   139       Bad  33        16
## 396 12.57       138    108          17        203   128      Good  33        14
## 397  6.14       139     23           3         37   120    Medium  55        11
## 398  7.41       162     26          12        368   159    Medium  40        18
## 399  5.94       100     79           7        284    95       Bad  50        12
## 400  9.71       134     37           0         27   120      Good  49        16
##     Urban  US
## 1     Yes Yes
## 2     Yes Yes
## 3     Yes Yes
## 4     Yes Yes
## 5     Yes  No
## 6      No Yes
## 7     Yes  No
## 8     Yes Yes
## 9      No  No
## 10     No Yes
## 11     No Yes
## 12    Yes Yes
## 13    Yes  No
## 14    Yes Yes
## 15    Yes Yes
## 16     No  No
## 17    Yes  No
## 18    Yes Yes
## 19     No Yes
## 20    Yes Yes
## 21    Yes Yes
## 22     No Yes
## 23    Yes  No
## 24    Yes  No
## 25    Yes Yes
## 26     No  No
## 27     No Yes
## 28    Yes  No
## 29    Yes Yes
## 30    Yes Yes
## 31    Yes  No
## 32    Yes Yes
## 33     No Yes
## 34    Yes Yes
## 35    Yes Yes
## 36     No Yes
## 37     No  No
## 38    Yes Yes
## 39    Yes  No
## 40     No  No
## 41     No  No
## 42    Yes  No
## 43    Yes  No
## 44    Yes Yes
## 45    Yes Yes
## 46    Yes Yes
## 47     No Yes
## 48    Yes  No
## 49    Yes  No
## 50    Yes  No
## 51    Yes Yes
## 52    Yes  No
## 53    Yes Yes
## 54    Yes Yes
## 55     No Yes
## 56    Yes Yes
## 57    Yes  No
## 58    Yes  No
## 59    Yes Yes
## 60    Yes  No
## 61    Yes Yes
## 62     No  No
## 63    Yes Yes
## 64    Yes Yes
## 65     No Yes
## 66     No  No
## 67    Yes  No
## 68    Yes Yes
## 69    Yes Yes
## 70    Yes  No
## 71    Yes Yes
## 72     No Yes
## 73    Yes  No
## 74     No Yes
## 75     No Yes
## 76     No Yes
## 77    Yes Yes
## 78     No Yes
## 79    Yes Yes
## 80    Yes  No
## 81    Yes Yes
## 82    Yes  No
## 83    Yes Yes
## 84    Yes Yes
## 85     No  No
## 86     No  No
## 87    Yes  No
## 88     No Yes
## 89    Yes Yes
## 90     No  No
## 91     No  No
## 92    Yes Yes
## 93    Yes  No
## 94    Yes  No
## 95    Yes Yes
## 96    Yes Yes
## 97     No Yes
## 98    Yes Yes
## 99     No Yes
## 100    No Yes
## 101    No Yes
## 102   Yes  No
## 103    No  No
## 104   Yes Yes
## 105   Yes  No
## 106   Yes Yes
## 107    No  No
## 108   Yes  No
## 109   Yes  No
## 110    No  No
## 111   Yes Yes
## 112   Yes Yes
## 113   Yes Yes
## 114   Yes Yes
## 115   Yes Yes
## 116   Yes  No
## 117    No  No
## 118   Yes  No
## 119   Yes Yes
## 120   Yes Yes
## 121   Yes Yes
## 122   Yes Yes
## 123   Yes Yes
## 124    No Yes
## 125   Yes  No
## 126    No  No
## 127   Yes Yes
## 128   Yes Yes
## 129   Yes Yes
## 130    No Yes
## 131   Yes Yes
## 132   Yes  No
## 133   Yes Yes
## 134   Yes Yes
## 135   Yes  No
## 136    No Yes
## 137    No  No
## 138   Yes  No
## 139   Yes Yes
## 140    No Yes
## 141   Yes Yes
## 142   Yes  No
## 143   Yes  No
## 144   Yes Yes
## 145    No  No
## 146   Yes Yes
## 147   Yes  No
## 148    No Yes
## 149    No Yes
## 150   Yes Yes
## 151    No Yes
## 152    No Yes
## 153    No  No
## 154    No Yes
## 155    No Yes
## 156   Yes  No
## 157   Yes  No
## 158    No Yes
## 159    No Yes
## 160    No  No
## 161    No  No
## 162    No Yes
## 163   Yes  No
## 164    No  No
## 165    No Yes
## 166   Yes Yes
## 167   Yes Yes
## 168   Yes  No
## 169   Yes  No
## 170   Yes Yes
## 171   Yes Yes
## 172   Yes Yes
## 173   Yes Yes
## 174   Yes Yes
## 175    No  No
## 176   Yes  No
## 177    No Yes
## 178   Yes Yes
## 179    No Yes
## 180   Yes Yes
## 181   Yes Yes
## 182   Yes  No
## 183   Yes  No
## 184   Yes Yes
## 185    No Yes
## 186   Yes Yes
## 187    No  No
## 188   Yes  No
## 189   Yes  No
## 190    No Yes
## 191    No Yes
## 192   Yes Yes
## 193    No  No
## 194   Yes Yes
## 195   Yes Yes
## 196   Yes Yes
## 197   Yes Yes
## 198   Yes  No
## 199   Yes Yes
## 200   Yes Yes
## 201    No  No
## 202   Yes  No
## 203    No Yes
## 204   Yes  No
## 205   Yes  No
## 206   Yes  No
## 207   Yes Yes
## 208    No  No
## 209   Yes  No
## 210    No Yes
## 211    No Yes
## 212   Yes Yes
## 213   Yes Yes
## 214   Yes Yes
## 215   Yes Yes
## 216   Yes Yes
## 217   Yes  No
## 218    No  No
## 219   Yes Yes
## 220   Yes Yes
## 221   Yes Yes
## 222   Yes  No
## 223   Yes Yes
## 224   Yes Yes
## 225    No  No
## 226   Yes  No
## 227   Yes  No
## 228   Yes Yes
## 229    No Yes
## 230    No  No
## 231    No  No
## 232    No  No
## 233   Yes Yes
## 234    No Yes
## 235    No Yes
## 236   Yes Yes
## 237   Yes Yes
## 238   Yes Yes
## 239   Yes  No
## 240   Yes Yes
## 241   Yes  No
## 242   Yes  No
## 243    No  No
## 244   Yes Yes
## 245   Yes  No
## 246    No Yes
## 247   Yes Yes
## 248   Yes  No
## 249   Yes Yes
## 250   Yes  No
## 251   Yes Yes
## 252   Yes Yes
## 253   Yes  No
## 254    No Yes
## 255   Yes Yes
## 256   Yes Yes
## 257   Yes  No
## 258   Yes Yes
## 259    No  No
## 260    No Yes
## 261   Yes Yes
## 262   Yes Yes
## 263   Yes Yes
## 264   Yes Yes
## 265   Yes Yes
## 266   Yes Yes
## 267    No Yes
## 268    No Yes
## 269   Yes  No
## 270   Yes  No
## 271   Yes  No
## 272   Yes  No
## 273   Yes  No
## 274   Yes Yes
## 275   Yes Yes
## 276   Yes Yes
## 277   Yes Yes
## 278   Yes Yes
## 279    No Yes
## 280   Yes Yes
## 281   Yes Yes
## 282    No Yes
## 283   Yes  No
## 284    No  No
## 285    No  No
## 286   Yes Yes
## 287    No Yes
## 288   Yes Yes
## 289    No  No
## 290   Yes Yes
## 291    No Yes
## 292   Yes  No
## 293   Yes Yes
## 294   Yes  No
## 295   Yes Yes
## 296    No Yes
## 297   Yes Yes
## 298   Yes Yes
## 299   Yes  No
## 300    No Yes
## 301   Yes Yes
## 302   Yes Yes
## 303   Yes Yes
## 304   Yes Yes
## 305   Yes Yes
## 306   Yes Yes
## 307   Yes Yes
## 308   Yes  No
## 309   Yes Yes
## 310   Yes Yes
## 311   Yes Yes
## 312   Yes Yes
## 313   Yes Yes
## 314   Yes  No
## 315   Yes Yes
## 316   Yes Yes
## 317   Yes Yes
## 318    No  No
## 319    No Yes
## 320    No Yes
## 321   Yes Yes
## 322   Yes  No
## 323   Yes Yes
## 324   Yes Yes
## 325   Yes Yes
## 326   Yes Yes
## 327   Yes  No
## 328   Yes Yes
## 329   Yes Yes
## 330   Yes Yes
## 331    No  No
## 332   Yes Yes
## 333   Yes Yes
## 334   Yes Yes
## 335   Yes Yes
## 336   Yes Yes
## 337   Yes  No
## 338   Yes  No
## 339   Yes  No
## 340   Yes Yes
## 341   Yes  No
## 342    No  No
## 343    No Yes
## 344   Yes Yes
## 345    No Yes
## 346   Yes  No
## 347    No  No
## 348    No  No
## 349   Yes Yes
## 350    No Yes
## 351    No Yes
## 352    No Yes
## 353   Yes Yes
## 354    No Yes
## 355   Yes Yes
## 356   Yes  No
## 357   Yes  No
## 358   Yes Yes
## 359   Yes Yes
## 360   Yes Yes
## 361    No Yes
## 362    No Yes
## 363   Yes Yes
## 364   Yes  No
## 365   Yes Yes
## 366    No  No
## 367    No Yes
## 368   Yes  No
## 369    No Yes
## 370   Yes Yes
## 371   Yes Yes
## 372   Yes  No
## 373    No  No
## 374   Yes  No
## 375   Yes Yes
## 376   Yes  No
## 377   Yes Yes
## 378    No  No
## 379   Yes Yes
## 380   Yes  No
## 381   Yes Yes
## 382   Yes Yes
## 383   Yes Yes
## 384   Yes  No
## 385   Yes Yes
## 386   Yes Yes
## 387   Yes  No
## 388    No Yes
## 389   Yes Yes
## 390   Yes Yes
## 391   Yes Yes
## 392   Yes  No
## 393   Yes Yes
## 394    No Yes
## 395   Yes Yes
## 396   Yes Yes
## 397    No Yes
## 398   Yes Yes
## 399   Yes Yes
## 400   Yes Yes</code></pre>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_spec</span> <span class="op">%&gt;%</span> 
  <span class="fu">fit</span><span class="op">(</span><span class="va">Sales</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">Income</span><span class="op">:</span><span class="va">Advertising</span> <span class="op">+</span> <span class="va">Price</span><span class="op">:</span><span class="va">Age</span>, data <span class="op">=</span> <span class="va">Carseats</span><span class="op">)</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  4ms 
## 
## Call:
## stats::lm(formula = Sales ~ . + Income:Advertising + Price:Age, 
##     data = data)
## 
## Coefficients:
##        (Intercept)           CompPrice              Income         Advertising  
##          6.5755654           0.0929371           0.0108940           0.0702462  
##         Population               Price       ShelveLocGood     ShelveLocMedium  
##          0.0001592          -0.1008064           4.8486762           1.9532620  
##                Age           Education            UrbanYes               USYes  
##         -0.0579466          -0.0208525           0.1401597          -0.1575571  
## Income:Advertising           Price:Age  
##          0.0007510           0.0001068</code></pre>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rec_spec</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">Sales</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Carseats</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">step_interact</span><span class="op">(</span><span class="op">~</span> <span class="va">Income</span><span class="op">:</span><span class="va">Advertising</span> <span class="op">+</span> <span class="va">Price</span><span class="op">:</span><span class="va">Age</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_model</span><span class="op">(</span><span class="va">lm_spec</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">rec_spec</span><span class="op">)</span>

<span class="va">lm_wf</span> <span class="op">%&gt;%</span> <span class="fu">fit</span><span class="op">(</span><span class="va">Carseats</span><span class="op">)</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: linear_reg()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 2 Recipe Steps
## 
## • step_dummy()
## • step_interact()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
##          (Intercept)             CompPrice                Income  
##            6.5755654             0.0929371             0.0108940  
##          Advertising            Population                 Price  
##            0.0702462             0.0001592            -0.1008064  
##                  Age             Education        ShelveLoc_Good  
##           -0.0579466            -0.0208525             4.8486762  
##     ShelveLoc_Medium             Urban_Yes                US_Yes  
##            1.9532620             0.1401597            -0.1575571  
## Income_x_Advertising           Price_x_Age  
##            0.0007510             0.0001068</code></pre>
</div>
<div id="writing-functions" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> Writing functions<a class="anchor" aria-label="anchor" href="#writing-functions"><i class="fas fa-link"></i></a>
</h2>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="statististical-learning.html"><span class="header-section-number">2</span> Statististical learning</a></div>
<div class="next"><a href="classification.html"><span class="header-section-number">4</span> Classification</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-regression"><span class="header-section-number">3</span> Linear Regression</a></li>
<li><a class="nav-link" href="#libraries"><span class="header-section-number">3.1</span> Libraries</a></li>
<li><a class="nav-link" href="#simple-linear-regression"><span class="header-section-number">3.2</span> Simple linear regression</a></li>
<li><a class="nav-link" href="#multiple-linear-regression"><span class="header-section-number">3.3</span> Multiple linear regression</a></li>
<li><a class="nav-link" href="#interaction-terms"><span class="header-section-number">3.4</span> Interaction terms</a></li>
<li><a class="nav-link" href="#non-linear-transformations-of-the-predictors"><span class="header-section-number">3.5</span> Non-linear transformations of the predictors</a></li>
<li><a class="nav-link" href="#qualitative-predictors"><span class="header-section-number">3.6</span> Qualitative predictors</a></li>
<li><a class="nav-link" href="#writing-functions"><span class="header-section-number">3.7</span> Writing functions</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>ISLR tidymodels Labs</strong>" was written by Emil Hvitfeldt. It was last built on 2021-05-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
